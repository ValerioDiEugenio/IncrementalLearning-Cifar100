{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IncrementalLearning_definitive.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r22uzGipUunu"
      },
      "source": [
        "from torchvision.datasets import CIFAR100\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class iCIFAR100(CIFAR100):\n",
        "    def __init__(self,root,\n",
        "                 train=True,\n",
        "                 transform=None,\n",
        "                 target_transform=None,\n",
        "                 test_transform=None,\n",
        "                 target_test_transform=None,\n",
        "                 download=False):\n",
        "        super(iCIFAR100,self).__init__(root,\n",
        "                                       train=train,\n",
        "                                       transform=transform,\n",
        "                                       target_transform=target_transform,\n",
        "                                       download=download)\n",
        "\n",
        "        self.target_test_transform=target_test_transform\n",
        "        self.test_transform=test_transform\n",
        "        self.TrainData = []\n",
        "        self.TrainLabels = []\n",
        "        self.TestData = []\n",
        "        self.TestLabels = []\n",
        "\n",
        "    def concatenate(self,datas,labels):\n",
        "        con_data=datas[0]\n",
        "        con_label=labels[0]\n",
        "        for i in range(1,len(datas)):\n",
        "            con_data=np.concatenate((con_data,datas[i]),axis=0)\n",
        "            con_label=np.concatenate((con_label,labels[i]),axis=0)\n",
        "        return con_data,con_label\n",
        "\n",
        "    def getTestData(self, classes):\n",
        "        datas,labels=[],[]\n",
        "        for label in range(classes[0], classes[1]):\n",
        "            data = self.data[np.array(self.targets) == label]\n",
        "            datas.append(data)\n",
        "            labels.append(np.full((data.shape[0]), label))\n",
        "        datas,labels=self.concatenate(datas,labels)\n",
        "        self.TestData=datas if self.TestData==[] else np.concatenate((self.TestData,datas),axis=0)\n",
        "        self.TestLabels=labels if self.TestLabels==[] else np.concatenate((self.TestLabels,labels),axis=0)\n",
        "        print(\"the size of test set is %s\"%(str(self.TestData.shape)))\n",
        "        print(\"the size of test label is %s\"%str(self.TestLabels.shape))\n",
        "\n",
        "\n",
        "    def getTrainData(self,classes,exemplar_set):\n",
        "\n",
        "        datas,labels=[],[]\n",
        "        if len(exemplar_set)!=0:\n",
        "            datas=[exemplar for exemplar in exemplar_set ]\n",
        "            length=len(datas[0])\n",
        "            labels=[np.full((length),label) for label in range(len(exemplar_set))]\n",
        "\n",
        "        for label in range(classes[0],classes[1]):\n",
        "            data=self.data[np.array(self.targets)==label]\n",
        "            datas.append(data)\n",
        "            labels.append(np.full((data.shape[0]),label))\n",
        "        self.TrainData,self.TrainLabels=self.concatenate(datas,labels)\n",
        "        print(\"the size of train set is %s\"%(str(self.TrainData.shape)))\n",
        "        print(\"the size of train label is %s\"%str(self.TrainLabels.shape))\n",
        "\n",
        "    def getTestDataCurrentClasses(self, classes):\n",
        "        datas,labels=[],[]\n",
        "        for label in range(classes[0],classes[1]):\n",
        "            data = self.data[np.array(self.targets) == label]\n",
        "            datas.append(data)\n",
        "            labels.append(np.full((data.shape[0]), label))\n",
        "        datas,labels=self.concatenate(datas,labels)\n",
        "        self.TestData=datas \n",
        "        self.TestLabels=labels \n",
        "        print(\"the size of test current classses set is %s\"%(str(self.TestData.shape)))\n",
        "        print(\"the size of test label current classes is %s\"%str(self.TestLabels.shape))\n",
        "\n",
        "    def getTrainItem(self,index):\n",
        "        img, target = Image.fromarray(self.TrainData[index]), self.TrainLabels[index]\n",
        "\n",
        "        if self.transform:\n",
        "            img=self.transform(img)\n",
        "\n",
        "        if self.target_transform:\n",
        "            target=self.target_transform(target)\n",
        "\n",
        "        return index,img,target\n",
        "\n",
        "    def getTestItem(self,index):\n",
        "        img, target = Image.fromarray(self.TestData[index]), self.TestLabels[index]\n",
        "\n",
        "        if self.test_transform:\n",
        "            img=self.test_transform(img)\n",
        "\n",
        "        if self.target_test_transform:\n",
        "            target=self.target_test_transform(target)\n",
        "\n",
        "        return index, img, target\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.TrainData!=[]:\n",
        "            return self.getTrainItem(index)\n",
        "        elif self.TestData!=[]:\n",
        "            return self.getTestItem(index)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.TrainData!=[]:\n",
        "            return len(self.TrainData)\n",
        "        elif self.TestData!=[]:\n",
        "            return len(self.TestData)\n",
        "\n",
        "    def get_image_class(self,label):\n",
        "        return self.data[np.array(self.targets)==label]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6Ay9wPLUjdN"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "__all__ = ['ResNet', 'resnet18_cbam', 'resnet34_cbam', 'resnet50_cbam', 'resnet101_cbam',\n",
        "           'resnet152_cbam']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.sequential = nn.Sequential(\n",
        "                   \n",
        "        Flatten(),\n",
        "        nn.Linear(in_planes, in_planes // 16, bias=False),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_planes // 16, in_planes,  bias=False),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        avg_out = self.sequential(self.avg_pool(x))\n",
        "        max_out = self.sequential(self.max_pool(x))\n",
        "        out = avg_out + max_out\n",
        "        return F.sigmoid( out ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "\n",
        "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
        "        padding = 3 if kernel_size == 7 else 1\n",
        "\n",
        "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print('输入的shape为:'+str(x.shape))\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        #print('avg_out的shape为:' + str(avg_out.shape))\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        #print('max_out的shape为:' + str(max_out.shape))\n",
        "        x = torch.cat([avg_out, max_out], dim=1)\n",
        "        x = self.conv1(x)\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "       # self.ca = ChannelAttention(planes)\n",
        "       # self.sa = SpatialAttention()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        \n",
        "       # out = self.ca(out) * out\n",
        "       # out = self.sa(out) * out\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.ca = ChannelAttention(planes * 4)\n",
        "        self.sa = SpatialAttention()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "       # out = self.ca(out) * out\n",
        "        #out = self.sa(out) * out\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=100):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.feature = nn.AvgPool2d(4, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.feature(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        #y=torch.norm(x,p=2,dim=1,keepdim=True)\n",
        "        #x/=y\n",
        "        #x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def resnet18_cbam(pretrained=False, **kwargs):\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAiIl2O-l8Vf"
      },
      "source": [
        "class CosineLinear(nn.Module):\t\n",
        "    def __init__(self, in_features, out_features, sigma=True):\t\n",
        "        super(CosineLinear, self).__init__()\t\n",
        "        self.in_features = in_features\t\n",
        "        self.out_features = out_features\t\n",
        "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\t\n",
        "        if sigma:\t\n",
        "            self.sigma = nn.Parameter(torch.Tensor(1))\t\n",
        "        else:\t\n",
        "            self.register_parameter('sigma', None)\t\n",
        "        print(self.sigma)\n",
        "        self.reset_parameters()\t\n",
        "\n",
        "    def reset_parameters(self):\t\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\t\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.sigma is not None:\t\n",
        "            self.sigma.data.fill_(1) #for initializaiton of sigma\t\n",
        "\n",
        "    def forward(self, input):\t\n",
        "        out = F.linear(F.normalize(input, p=2,dim=1), F.normalize(self.weight, p=2, dim=1))\t\n",
        "        if self.sigma is not None:\t\n",
        "            out = self.sigma * out\t\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylASApTalw-5"
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, last=False):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "       # self.ca = ChannelAttention(planes)\n",
        "       # self.sa = SpatialAttention()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.last=last\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        \n",
        "       # out = self.ca(out) * out\n",
        "       # out = self.sa(out) * out\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        if not self.last:\n",
        "          out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ResNetCosine(nn.Module):\n",
        "\n",
        "  \n",
        "\n",
        "    def __init__(self, block, layers, num_classes=100):\n",
        "        self.inplanes = 64\n",
        "        super(ResNetCosine, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, last_phase=True)\n",
        "        self.feature = nn.AvgPool2d(4, stride=1)\n",
        "        self.fc = CosineLinear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, last_phase=False):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        if last_phase:\n",
        "          for i in range(1, blocks-1):\n",
        "            layers.append(block(self.inplanes, planes, last=True))\n",
        "        else:\n",
        "          for i in range(1, blocks):\n",
        "                layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.feature(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        #x = torch.nn.functional.normalize(x, p=2, dim=1)\n",
        "        #y=torch.norm(x,p=2,dim=1,keepdim=True)\n",
        "        #x/=y\n",
        "        #x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def resnet18_cbamCosine(pretrained=False, **kwargs):\n",
        "   \n",
        "    model = ResNetCosine(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OsRk1prU4R4"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class network(nn.Module):\n",
        "\n",
        "    def __init__(self, numclass, feature_extractor):\n",
        "        super(network, self).__init__()\n",
        "        self.feature = feature_extractor\n",
        "        self.fc = nn.Linear(feature_extractor.fc.in_features, numclass, bias=True)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.feature(input)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def Incremental_learning(self, numclass):\n",
        "        weight = self.fc.weight.data\n",
        "        bias = self.fc.bias.data\n",
        "        in_feature = self.fc.in_features\n",
        "        out_feature = self.fc.out_features\n",
        "\n",
        "        self.fc = nn.Linear(in_feature, numclass, bias=True)\n",
        "        self.fc.weight.data[:out_feature] = weight\n",
        "        self.fc.bias.data[:out_feature] = bias\n",
        "\n",
        "    def feature_extractor(self,inputs):\n",
        "        return self.feature(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO8E4XlOYa_a"
      },
      "source": [
        "from torchvision.datasets import CIFAR100\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision.datasets import CIFAR100\n",
        "from PIL import Image\n",
        "import sys\n",
        "import copy\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "from itertools import groupby\n",
        "import torchvision.models as models\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import math\n",
        "from torch.nn import functional as F\n",
        "device = 'cuda'\n",
        "from torch.nn import BCEWithLogitsLoss \n",
        "from sklearn.metrics import confusion_matrix\n",
        "class Finetuning:\n",
        "      def __init__(self,numclass,feature_extractor,batch_size,task_size,memory_size,epochs,learning_rate):\n",
        "        super(Finetuning, self).__init__()\n",
        "        self.epochs=epochs\n",
        "        self.learning_rate=learning_rate\n",
        "        self.net = network(100, feature_extractor) # 100\n",
        "        self.numclass = numclass\n",
        "        self.transform = transforms.Compose([\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
        "        self.old_model = None\n",
        "\n",
        "        self.train_transform = transforms.Compose([\n",
        "                                                  transforms.RandomCrop(32, padding=4),\n",
        "                                                  transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                                  transforms.ToTensor(),\n",
        "                                                  transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
        "        \n",
        "        self.test_transform = transforms.Compose([\n",
        "                                                  transforms.ToTensor(),\n",
        "                                                  transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
        "        self.test_current_transform = transforms.Compose([\n",
        "                                                  transforms.ToTensor(),\n",
        "                                                  transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.train_dataset = iCIFAR100('dataset', transform=self.train_transform, download=True)\n",
        "        self.test_dataset = iCIFAR100('dataset', test_transform=self.test_transform, train=False, download=True)\n",
        "        self.test_current_classes = iCIFAR100('dataset', test_transform=self.test_transform,train = False,download=True)\n",
        "\n",
        "        rng = np.random.default_rng()\n",
        "        h = rng.choice(100, size=100, replace= False)\n",
        "        dic = {i:h[i] for i in range(100)}\n",
        "\n",
        "        self.batchsize = batch_size\n",
        "        self.memory_size=memory_size\n",
        "        self.task_size=task_size\n",
        "\n",
        "        self.train_dataset.targets = [ dic[self.train_dataset.targets[i]] for i in range(len(self.train_dataset.targets))]\n",
        "        self.test_dataset.targets = [ dic[self.test_dataset.targets[i]] for i in range(len(self.test_dataset.targets))]\n",
        "        self.test_current_classes.targets = [ dic[self.test_current_classes.targets[i]] for i in range(len(self.test_current_classes.targets))]\n",
        "\n",
        "        self.batchsize = batch_size\n",
        "        self.memory_size=memory_size\n",
        "        self.task_size=task_size\n",
        "\n",
        "        self.train_loader=None\n",
        "        self.test_loader=None\n",
        "        self.test_current_classes_loader = None\n",
        "      \n",
        "\n",
        "      def _get_train_and_test_dataloader(self, classes):\n",
        "        self.test_current_classes.getTestDataCurrentClasses(classes)\n",
        "        self.train_dataset.getTrainData(classes, [])\n",
        "        self.test_dataset.getTestData(classes)\n",
        "        train_loader = DataLoader(dataset=self.train_dataset,\n",
        "                                  shuffle=True,\n",
        "                                  batch_size=self.batchsize)\n",
        "\n",
        "        test_loader = DataLoader(dataset=self.test_dataset,\n",
        "                                 shuffle=True,\n",
        "                                 batch_size=self.batchsize)\n",
        "        \n",
        "        test_current_classes_loader = DataLoader(dataset=self.test_current_classes,\n",
        "                                 shuffle=True,\n",
        "                                 batch_size=self.batchsize)\n",
        "\n",
        "        return train_loader, test_loader,test_current_classes_loader\n",
        "\n",
        "      def train(self):\n",
        "        \n",
        "        classes=[self.numclass-self.task_size,self.numclass]\n",
        "        self.train_loader,self.test_loader,self.test_current_classes_loader=self._get_train_and_test_dataloader(classes)\n",
        "        self.net.train()\n",
        "        self.net.to(device)\n",
        "\n",
        "        opt = optim.SGD(self.net.parameters(), lr=self.learning_rate, momentum=0.9, weight_decay=0.00001)\n",
        "        for epoch in range(self.epochs):\n",
        "            if epoch == 48:\n",
        "                for p in opt.param_groups:\n",
        "                  p['lr'] =self.learning_rate/ 5\n",
        "                print(\"change learning rate:%.3f\" % (self.learning_rate / 5))\n",
        "            if epoch == 62:\n",
        "                for p in opt.param_groups:\n",
        "                  p['lr'] =self.learning_rate/ 25\n",
        "                print(\"change learning rate:%.3f\" % (self.learning_rate / 25))\n",
        "            for step, (indexs, images, target) in enumerate(self.train_loader):\n",
        "                # load train images and target into model\n",
        "                images, target = images.to(device), target.to(device)\n",
        "                #compute bce loss\n",
        "                loss_value = self._compute_loss(indexs, images, target,\"BCE_Logits\") #passa parametro per cambiare il loss\n",
        "                #zeroes grad structures \n",
        "                opt.zero_grad()\n",
        "                #calculate \n",
        "                loss_value.backward()\n",
        "                opt.step()\n",
        "                print('epoch:%d,step:%d,loss:%.3f' % (epoch, step, loss_value.item()))\n",
        "            \n",
        "            accuracy_el = self._test(self.test_loader)\n",
        "\n",
        "            print('epoch:%d,accuracy:%.3f' % (epoch,accuracy_el))\n",
        "\n",
        "            # calculate accuracy on validation set\n",
        "        accuracy_el = self._test(self.test_loader)\n",
        "        accuracy_c = self._test(self.test_current_classes_loader)\n",
        "\n",
        "\n",
        "        print('epoch:%d,test_accuracy:%.3f' % (epoch, accuracy_el))\n",
        "        self.numclass+=self.task_size  \n",
        "        return [accuracy_el,accuracy_c]\n",
        "\n",
        "      def _test(self, testloader):\n",
        "        self.net.eval()\n",
        "        correct, total = 0, 0\n",
        "        for setp, (indexs, imgs, labels) in enumerate(testloader):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = self.net(imgs) \n",
        "            predicts = torch.max(outputs, dim=1)[1] \n",
        "            correct += (predicts.cpu() == labels.cpu()).sum()\n",
        "            total += len(labels)\n",
        "        accuracy = 100 * correct / total\n",
        "        self.net.train()\n",
        "        return accuracy\n",
        "\n",
        "      def _val(self, testloader): \n",
        "        self.net.eval()\n",
        "        correct, total = 0, 0\n",
        "        for setp, (indexs, imgs, labels) in enumerate(testloader):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = self.net(imgs)\n",
        "            predicts = torch.max(outputs, dim=1)[1]\n",
        "            correct += (predicts.cpu() == labels.cpu()).sum()\n",
        "            total += len(labels)\n",
        "        accuracy = 100 * correct / total\n",
        "        self.net.train()\n",
        "        return accuracy\n",
        "\n",
        "      def _compute_loss(self, indexs, imgs, target,loss):\n",
        "        output=self.net(imgs)\n",
        "        target = self.get_one_hot(target, 100)\n",
        "        output, target = output.to(device), target.to(device)\n",
        "        if loss == \"BCE_Logits\": criterion= BCEWithLogitsLoss()\n",
        "        if loss == \"hinge\" : criterion= torch.nn.HingeEmbeddingLoss(margin=1.0, \n",
        "                                                 size_average=None, reduce=None, reduction='mean')\n",
        "        if loss == \"MSE\" : criterion = torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
        "        if loss == \"Cross\" : criterion = torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n",
        "        if self.old_model == None:\n",
        "            return criterion(output, target)\n",
        "        else:\n",
        "            old_target=torch.sigmoid(self.old_model(imgs))\n",
        "            old_task_size = old_target.shape[1]\n",
        "            target[..., :old_task_size] = old_target\n",
        "            return criterion(output, target)\n",
        "    \n",
        "    \n",
        "      def get_one_hot(self,target,num_class):\n",
        "        one_hot=torch.zeros(target.shape[0],num_class).to(device)\n",
        "        one_hot=one_hot.scatter(dim=1,index=target.long().view(-1,1),value=1.)\n",
        "        return one_hot\n",
        "\n",
        "     \n",
        "      def getNet(self):\n",
        "        return copy.deepcopy(self.net)\n",
        "\n",
        "      def getTestLoader(self):\n",
        "        return self.test_loader\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P26s_Q38iHgm"
      },
      "source": [
        "class jointTraining:\n",
        "  def __init__(self,numclass,feature_extractor,batch_size,task_size,memory_size,epochs,learning_rate):\n",
        "        super(jointTraining, self).__init__()\n",
        "        self.epochs=epochs\n",
        "        self.learning_rate=learning_rate\n",
        "        self.net = network(100, feature_extractor) # 100\n",
        "        self.numclass = numclass\n",
        "        self.transform = transforms.Compose([\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
        "        self.old_model = None\n",
        "\n",
        "        self.train_transform = transforms.Compose([\n",
        "                                                  transforms.RandomCrop(32, padding=4),\n",
        "                                                  transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                                  transforms.ToTensor(),\n",
        "                                                  transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
        "        \n",
        "        self.test_transform = transforms.Compose([\n",
        "                                                  transforms.ToTensor(),\n",
        "                                                  transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
        "        \n",
        "        self.classify_transform=transforms.Compose([transforms.RandomHorizontalFlip(p=1.),\n",
        "                                                    \n",
        "                                                    transforms.ToTensor(),\n",
        "                                                    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
        "        \n",
        "        self.train_dataset = iCIFAR100('dataset', transform=self.train_transform, download=True)\n",
        "        self.test_dataset = iCIFAR100('dataset', test_transform=self.test_transform, train=False, download=True)\n",
        "        \n",
        "\n",
        "        self.batchsize = batch_size\n",
        "        self.memory_size=memory_size\n",
        "        self.task_size=task_size\n",
        "\n",
        "        self.train_loader=None\n",
        "        self.test_loader=None\n",
        "\n",
        "  def _get_train_and_test_dataloader(self, classes):\n",
        "        self.train_dataset.getTrainData(classes, [])\n",
        "        self.test_dataset.getTestData(classes)\n",
        "        train_loader = DataLoader(dataset=self.train_dataset,\n",
        "                                  shuffle=True,\n",
        "                                  batch_size=self.batchsize,\n",
        "                                  num_workers=4)\n",
        "\n",
        "        test_loader = DataLoader(dataset=self.test_dataset,\n",
        "                                 shuffle=True,\n",
        "                                 batch_size=self.batchsize,\n",
        "                                 num_workers=4)\n",
        "        return train_loader, test_loader\n",
        "\n",
        "  def train(self):\n",
        "        \n",
        "        classes=[0,self.numclass]\n",
        "        self.train_loader,self.test_loader=self._get_train_and_test_dataloader(classes)\n",
        "        self.net.train()\n",
        "        self.net.to(device)\n",
        "\n",
        "        opt = optim.SGD(self.net.parameters(), lr=self.learning_rate, momentum=0.9, weight_decay=0.00001)\n",
        "        for epoch in range(self.epochs):\n",
        "            if epoch == 48:\n",
        "                for p in opt.param_groups:\n",
        "                  p['lr'] =self.learning_rate/ 5\n",
        "                print(\"change learning rate:%.3f\" % (self.learning_rate / 5))\n",
        "            if epoch == 62:\n",
        "                for p in opt.param_groups:\n",
        "                  p['lr'] =self.learning_rate/ 25\n",
        "                print(\"change learning rate:%.3f\" % (self.learning_rate / 25))\n",
        "            for step, (indexs, images, target) in enumerate(self.train_loader):\n",
        "                # load train images and target into model\n",
        "                images, target = images.to(device), target.to(device)\n",
        "                #compute bce loss\n",
        "                loss_value = self._compute_loss(indexs, images, target,\"BCE_Logits\") #passa parametro per cambiare il loss\n",
        "                #zeroes grad structures \n",
        "                opt.zero_grad()\n",
        "                #calculate \n",
        "                loss_value.backward()\n",
        "                opt.step()\n",
        "                print('epoch:%d,step:%d,loss:%.3f' % (epoch, step, loss_value.item()))\n",
        "            accuracy_el = self._test(self.test_loader)\n",
        "            print('epoch:%d,accuracy:%.3f' % (epoch,accuracy_el))\n",
        "\n",
        "            # calculate accuracy on validation set\n",
        "        accuracy_el = self._test(self.test_loader)\n",
        "\n",
        "  def _test(self, testloader):\n",
        "        self.net.eval()\n",
        "        correct, total = 0, 0\n",
        "        for setp, (indexs, imgs, labels) in enumerate(testloader):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = self.net(imgs) \n",
        "            predicts = torch.max(outputs, dim=1)[1] \n",
        "            correct += (predicts.cpu() == labels.cpu()).sum()\n",
        "            total += len(labels)\n",
        "        accuracy = 100 * correct / total\n",
        "        self.net.train()\n",
        "        return accuracy\n",
        "\n",
        "        print('epoch:%d,test_accuracy:%.3f' % (epoch, accuracy_el))\n",
        "        self.numclass+=self.task_size  \n",
        "        return accuracy_el\n",
        "        \n",
        "  def _compute_loss(self, indexs, imgs, target,loss):\n",
        "        output=self.net(imgs)\n",
        "        target = self.get_one_hot(target, 100)\n",
        "        output, target = output.to(device), target.to(device)\n",
        "        if loss == \"BCE_Logits\": criterion= BCEWithLogitsLoss()\n",
        "        if loss == \"hinge\" : criterion= torch.nn.HingeEmbeddingLoss(margin=1.0, \n",
        "                                                 size_average=None, reduce=None, reduction='mean')\n",
        "        if loss == \"MSE\" : criterion = torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
        "        if loss == \"Cross\" : criterion = torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n",
        "        if self.old_model == None:\n",
        "            return criterion(output, target)\n",
        "        else:\n",
        "            old_target=torch.sigmoid(self.old_model(imgs))\n",
        "            old_task_size = old_target.shape[1]\n",
        "            target[..., :old_task_size] = old_target\n",
        "            return criterion(output, target)\n",
        "    \n",
        "    \n",
        "  def get_one_hot(self,target,num_class):\n",
        "        one_hot=torch.zeros(target.shape[0],num_class).to(device)\n",
        "        one_hot=one_hot.scatter(dim=1,index=target.long().view(-1,1),value=1.)\n",
        "        return one_hot\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtJt3CHtd22k"
      },
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from torch.nn import functional as F\n",
        "from PIL import Image\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = 'cuda'\n",
        "def get_one_hot(target,num_class):\n",
        "    one_hot=torch.zeros(target.shape[0],num_class).to(device)\n",
        "    one_hot=one_hot.scatter(dim=1,index=target.long().view(-1,1),value=1.)\n",
        "    return one_hot\n",
        "\n",
        "class LWF:\n",
        "\n",
        "    def __init__(self,numclass,feature_extractor,batch_size,task_size,memory_size,epochs,learning_rate):\n",
        "\n",
        "        super(LWF, self).__init__()\n",
        "        self.epochs=epochs\n",
        "        self.learning_rate=learning_rate\n",
        "        self.model = network(numclass,feature_extractor)\n",
        "        self.exemplar_set = []\n",
        "        self.class_mean_set = []\n",
        "        self.numclass = numclass\n",
        "        self.transform = transforms.Compose([#transforms.Resize(img_size),\n",
        "                                             transforms.ToTensor(),\n",
        "                                            transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
        "        self.old_model = None\n",
        "\n",
        "        self.train_transform = transforms.Compose([#transforms.Resize(img_size),\n",
        "                                                  transforms.RandomCrop((32,32),padding=4),\n",
        "                                                  transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                                  \n",
        "                                                  transforms.ToTensor(),\n",
        "                                                  transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
        "        \n",
        "        self.test_transform = transforms.Compose([#transforms.Resize(img_size),\n",
        "                                                   transforms.ToTensor(),\n",
        "                                                 transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
        "        \n",
        "        self.classify_transform=transforms.Compose([transforms.RandomHorizontalFlip(p=1.),\n",
        "                                                    #transforms.Resize(img_size),\n",
        "                                                    transforms.ToTensor(),\n",
        "                                                   transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
        "        \n",
        "        self.train_dataset = iCIFAR100('dataset', transform=self.train_transform, download=True)\n",
        "        self.test_dataset = iCIFAR100('dataset', test_transform=self.test_transform, train=False, download=True)\n",
        "        self.test_current_classes = iCIFAR100('dataset', test_transform=self.test_transform,train = False, download=True)\n",
        "\n",
        "\n",
        "        rng = np.random.default_rng()\n",
        "        h = rng.choice(100, size=100, replace= False)\n",
        "        dic = {i:h[i] for i in range(100)}\n",
        "        self.batchsize = batch_size\n",
        "        self.memory_size=memory_size\n",
        "        self.task_size=task_size\n",
        "\n",
        "        self.train_dataset.targets = [ dic[self.train_dataset.targets[i]] for i in range(len(self.train_dataset.targets))]\n",
        "        self.test_dataset.targets = [ dic[self.test_dataset.targets[i]] for i in range(len(self.test_dataset.targets))]\n",
        "        self.test_current_classes.targets = [ dic[self.test_current_classes.targets[i]] for i in range(len(self.test_current_classes.targets))]\n",
        "        self.batchsize = batch_size\n",
        "        self.memory_size=memory_size\n",
        "        self.task_size=task_size\n",
        "\n",
        "        self.train_loader=None\n",
        "        self.test_loader=None\n",
        "        self.test_current_classes_loader = None\n",
        "\n",
        "    # get incremental train data\n",
        "    # incremental        \n",
        "\n",
        "    def _get_train_and_test_dataloader(self, classes):\n",
        "        self.test_current_classes.getTestDataCurrentClasses(classes)\n",
        "        self.train_dataset.getTrainData(classes, self.exemplar_set)\n",
        "        self.test_dataset.getTestData(classes)\n",
        "        train_loader = DataLoader(dataset=self.train_dataset,\n",
        "                                  shuffle=True,\n",
        "                                  batch_size=self.batchsize)\n",
        "\n",
        "        test_loader = DataLoader(dataset=self.test_dataset,\n",
        "                                 shuffle=True,\n",
        "                                 batch_size=self.batchsize)\n",
        "        \n",
        "        test_current_classes_loader = DataLoader(dataset=self.test_current_classes,\n",
        "                                 shuffle=True,\n",
        "                                 batch_size=self.batchsize)\n",
        "\n",
        "        return train_loader, test_loader,test_current_classes_loader\n",
        "    \n",
        " \n",
        "    # train model\n",
        "    # compute loss\n",
        "    # evaluate model\n",
        "    def train(self):\n",
        "        classes=[self.numclass-self.task_size,self.numclass]\n",
        "        self.train_loader,self.test_loader, self.test_current_classes_loader=self._get_train_and_test_dataloader(classes)\n",
        "        if self.numclass>self.task_size:\n",
        "            self.model.Incremental_learning(self.numclass)\n",
        "        self.model.train()\n",
        "        self.model.to(device)\n",
        "        accuracy = 0\n",
        "        opt = optim.SGD(self.model.parameters(), lr=self.learning_rate, weight_decay=0.00001)\n",
        "        for epoch in range(self.epochs):\n",
        "            if epoch == 48:\n",
        "                if self.numclass==self.task_size:\n",
        "                     print(1)\n",
        "                     opt = optim.SGD(self.model.parameters(), lr=self.learning_rate /5, weight_decay=0.00001)\n",
        "                else:\n",
        "                     for p in opt.param_groups:\n",
        "                         p['lr'] =self.learning_rate/ 5\n",
        "                     #opt = optim.SGD(self.model.parameters(), lr=self.learning_rate/ 5,weight_decay=0.00001,momentum=0.9,nesterov=True,)\n",
        "                print(\"change learning rate:%.3f\" % (self.learning_rate / 5))\n",
        "            elif epoch == 62:\n",
        "                if self.numclass>self.task_size:\n",
        "                     for p in opt.param_groups:\n",
        "                         p['lr'] =self.learning_rate/ 25\n",
        "                     #opt = optim.SGD(self.model.parameters(), lr=self.learning_rate/ 25,weight_decay=0.00001,momentum=0.9,nesterov=True,)\n",
        "                else:\n",
        "                     opt = optim.SGD(self.model.parameters(), lr=self.learning_rate /25, weight_decay=0.00001)\n",
        "                print(\"change learning rate:%.3f\" % (self.learning_rate / 25))\n",
        "            \n",
        "            for step, (indexs, images, target) in enumerate(self.train_loader):\n",
        "                images, target = images.to(device), target.to(device)\n",
        "                #output = self.model(images)\n",
        "                loss_value = self._compute_loss(indexs, images, target)\n",
        "                opt.zero_grad()\n",
        "                loss_value.backward()\n",
        "                opt.step()\n",
        "                print('epoch:%d,step:%d,loss:%.3f' % (epoch, step, loss_value.item()))\n",
        "        accuracy = float(self._test(self.test_loader))\n",
        "        acc_c = float(self._test(self.test_current_classes_loader))\n",
        "        print('epoch:%d,accuracy:%.3f' % (epoch, accuracy))\n",
        "        self.numclass+=self.task_size\n",
        "        self.old_model=copy.deepcopy(self.model)\n",
        "        self.old_model.to(device)\n",
        "        self.old_model.eval()\n",
        "        return [accuracy,acc_c]\n",
        "\n",
        "    def _test(self, testloader):\n",
        "        self.model.eval()\n",
        "        correct, total = 0, 0\n",
        "        for setp, (indexs, imgs, labels) in enumerate(testloader):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(imgs) \n",
        "            predicts = torch.max(outputs, dim=1)[1] \n",
        "            correct += (predicts.cpu() == labels.cpu()).sum()\n",
        "            total += len(labels)\n",
        "        accuracy = 100 * correct / total\n",
        "        self.model.train()\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "    def _compute_loss(self, indexs, imgs, target):\n",
        "        output=self.model(imgs)\n",
        "        target = get_one_hot(target, self.numclass)\n",
        "        output, target = output.to(device), target.to(device)\n",
        "        if self.old_model == None:\n",
        "            return F.binary_cross_entropy_with_logits(output, target)\n",
        "        else:\n",
        "            #old_target = torch.tensor(np.array([self.old_model_output[index.item()] for index in indexs]))\n",
        "            old_target=torch.sigmoid(self.old_model(imgs))\n",
        "            old_task_size = old_target.shape[1]\n",
        "            target[..., :old_task_size] = old_target\n",
        "            return F.binary_cross_entropy_with_logits(output, target)\n",
        "    \n",
        "    def getNet(self):\n",
        "        return copy.deepcopy(self.old_model)\n",
        "\n",
        "    def getTestLoader(self):\n",
        "        return self.test_loader\n",
        "\n",
        "        \n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhOROyRJUZvg"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from torch.nn import functional as F\n",
        "from PIL import Image\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "device = 'cuda'\n",
        "def get_one_hot(target,num_class):\n",
        "    one_hot=torch.zeros(target.shape[0],num_class).to(device)\n",
        "    one_hot=one_hot.scatter(dim=1,index=target.long().view(-1,1),value=1.)\n",
        "    return one_hot\n",
        "\n",
        "class iCaRLmodel:\n",
        "\n",
        "    def __init__(self,numclass,feature_extractor,batch_size,task_size,memory_size,epochs,learning_rate):\n",
        "\n",
        "        super(iCaRLmodel, self).__init__()\n",
        "        self.epochs=epochs\n",
        "        self.learning_rate=learning_rate\n",
        "        self.model = network(numclass,feature_extractor)\n",
        "        self.exemplar_set = []\n",
        "        self.class_mean_set = []\n",
        "        self.numclass = numclass\n",
        "        self.n_neighbors=5\n",
        "        self.KNN_dataloader=None\n",
        "        self.C = 100\n",
        "        self.SVM_dataloader=None\n",
        "        self.random_selection=False\n",
        "\n",
        "        self.exemplars = [list() for i in range(100)]\n",
        "\n",
        "        self.transform = transforms.Compose([#transforms.Resize(img_size),\n",
        "                                             transforms.ToTensor(),\n",
        "                                            transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
        "        self.old_model = None\n",
        "\n",
        "        self.train_transform = transforms.Compose([#transforms.Resize(img_size),\n",
        "                                                  transforms.RandomCrop((32,32),padding=4),\n",
        "                                                  transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                                  transforms.ColorJitter(brightness=0.24705882352941178),\n",
        "                                                  transforms.ToTensor(),\n",
        "                                                  transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
        "        \n",
        "        self.test_transform = transforms.Compose([#transforms.Resize(img_size),\n",
        "                                                   transforms.ToTensor(),\n",
        "                                                 transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
        "        \n",
        "        self.classify_transform=transforms.Compose([transforms.RandomHorizontalFlip(p=1.),\n",
        "                                                    #transforms.Resize(img_size),\n",
        "                                                    transforms.ToTensor(),\n",
        "                                                   transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
        "        \n",
        "        self.train_dataset = iCIFAR100('dataset', transform=self.train_transform, download=True)\n",
        "        self.test_dataset = iCIFAR100('dataset', test_transform=self.test_transform, train=False, download=True)\n",
        "        self.test_current_classes = iCIFAR100('dataset', test_transform=self.test_transform, train = False, download=True)\n",
        "\n",
        "\n",
        "        rng = np.random.default_rng()\n",
        "        h = rng.choice(100, size=100, replace= False)\n",
        "        dic = {i:h[i] for i in range(100)}\n",
        "        self.batchsize = batch_size\n",
        "        self.memory_size=memory_size\n",
        "        self.task_size=task_size\n",
        "\n",
        "        self.train_dataset.targets = [ dic[self.train_dataset.targets[i]] for i in range(len(self.train_dataset.targets))]\n",
        "        self.test_dataset.targets = [ dic[self.test_dataset.targets[i]] for i in range(len(self.test_dataset.targets))]\n",
        "        self.test_current_classes.targets = [ dic[self.test_current_classes.targets[i]] for i in range(len(self.test_current_classes.targets))]\n",
        "\n",
        "        self.train_loader=None\n",
        "        self.test_loader=None\n",
        "        self.test_current_classes_loader=None\n",
        "\n",
        "    # get incremental train data\n",
        "    # incremental\n",
        "\n",
        "    def flattened_exemplars(self):\n",
        "        # trasforma la lista di liste di exemplar\n",
        "        # return list of indexes of exemplars\n",
        "        flat_list = []\n",
        "        for sublist in self.exemplars:\n",
        "            for item in sublist:\n",
        "                flat_list.append(item)\n",
        "        return flat_list\n",
        "\n",
        "    def beforeTrain(self):\n",
        "        self.model.eval()\n",
        "        classes=[self.numclass-self.task_size,self.numclass]\n",
        "        self.train_loader,self.test_loader,self.test_current_classes_loader=self._get_train_and_test_dataloader(classes)\n",
        "        if self.numclass>self.task_size:\n",
        "            self.model.Incremental_learning(self.numclass)\n",
        "        self.model.train()\n",
        "        self.model.to(device)\n",
        "\n",
        "    def _get_train_and_test_dataloader(self, classes):\n",
        "        self.test_current_classes.getTestDataCurrentClasses(classes)\n",
        "        self.train_dataset.getTrainData(classes, self.exemplar_set)\n",
        "        self.test_dataset.getTestData(classes)\n",
        "        train_loader = DataLoader(dataset=self.train_dataset,\n",
        "                                  shuffle=True,\n",
        "                                  batch_size=self.batchsize)\n",
        "\n",
        "        test_loader = DataLoader(dataset=self.test_dataset,\n",
        "                                 shuffle=True,\n",
        "                                 batch_size=self.batchsize)\n",
        "        \n",
        "        test_current_classes_loader = DataLoader(dataset=self.test_current_classes,\n",
        "                                 shuffle=True,\n",
        "                                 batch_size=self.batchsize)\n",
        "\n",
        "        return train_loader, test_loader,test_current_classes_loader\n",
        "    \n",
        "  \n",
        "    # train model\n",
        "    # compute loss\n",
        "    # evaluate model\n",
        "    def train(self):\n",
        "        accuracy = 0\n",
        "        opt = optim.SGD(self.model.parameters(), lr=self.learning_rate, weight_decay=0.00001)\n",
        "        for epoch in range(self.epochs):\n",
        "            if epoch == 48:\n",
        "                if self.numclass==self.task_size:\n",
        "                     print(1)\n",
        "                     opt = optim.SGD(self.model.parameters(), lr=self.learning_rate /5, weight_decay=0.00001)\n",
        "                else:\n",
        "                     for p in opt.param_groups:\n",
        "                         p['lr'] =self.learning_rate/ 5\n",
        "                     #opt = optim.SGD(self.model.parameters(), lr=self.learning_rate/ 5,weight_decay=0.00001,momentum=0.9,nesterov=True,)\n",
        "                print(\"change learning rate:%.3f\" % (self.learning_rate / 5))\n",
        "            elif epoch == 62:\n",
        "                if self.numclass>self.task_size:\n",
        "                     for p in opt.param_groups:\n",
        "                         p['lr'] =self.learning_rate/ 25\n",
        "                     #opt = optim.SGD(self.model.parameters(), lr=self.learning_rate/ 25,weight_decay=0.00001,momentum=0.9,nesterov=True,)\n",
        "                else:\n",
        "                     opt = optim.SGD(self.model.parameters(), lr=self.learning_rate /25, weight_decay=0.00001)\n",
        "                print(\"change learning rate:%.3f\" % (self.learning_rate / 25))\n",
        "            \n",
        "            for step, (indexs, images, target) in enumerate(self.train_loader):\n",
        "                for step, (indexs, images, target) in enumerate(self.train_loader):\n",
        "                  images, target = images.to(device), target.to(device)\n",
        "                  #output = self.model(images)\n",
        "                  loss_value = self._compute_loss(indexs, images, target)\n",
        "                  #loss_value = self.CE_L2_loss(indexs, images, target)\n",
        "                  #loss_value = self.L2_L2_loss(indexs, images, target)\n",
        "                  #loss_value = self.less_forget_constraints(images, target)\n",
        "                  opt.zero_grad()\n",
        "                  loss_value.backward()\n",
        "                  opt.step()\n",
        "                  print('epoch:%d,step:%d,loss:%.3f' % (epoch, step, loss_value.item()))\n",
        "            accuracy = self._test(self.test_loader, 1)\n",
        "            print('epoch:%d,accuracy:%.3f' % (epoch, accuracy))\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "    def _test(self, testloader, mode):\n",
        "        if mode==0:\n",
        "            #print(\"compute KNN\")\n",
        "            print(\"compute SVM\")\n",
        "        self.model.eval()\n",
        "        correct, total = 0, 0\n",
        "        for setp, (indexs, imgs, labels) in enumerate(testloader):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(imgs) if mode == 1 else self.classify(imgs) # change to 'classifyKNN' or classifySVM' to switch to another classifier\n",
        "            predicts = torch.max(outputs, dim=1)[1] if mode == 1 else outputs\n",
        "            correct += (predicts.cpu() == labels.cpu()).sum()\n",
        "            total += len(labels)\n",
        "        accuracy = 100 * correct / total\n",
        "        self.model.train()\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "    def _compute_loss(self, indexs, imgs, target):\n",
        "        output=self.model(imgs)\n",
        "        target = get_one_hot(target, self.numclass)\n",
        "        output, target = output.to(device), target.to(device)\n",
        "        if self.old_model == None:\n",
        "            return F.binary_cross_entropy_with_logits(output, target)\n",
        "        else:\n",
        "            #old_target = torch.tensor(np.array([self.old_model_output[index.item()] for index in indexs]))\n",
        "            old_target=torch.sigmoid(self.old_model(imgs))\n",
        "            old_task_size = old_target.shape[1]\n",
        "            target[..., :old_task_size] = old_target\n",
        "            return F.binary_cross_entropy_with_logits(output, target)\n",
        "\n",
        "\n",
        "   #DIFFERENT CLASSIFIER         \n",
        "\n",
        "    def training_KNN(self, n_neighbors):\n",
        "     \n",
        "        images_def= None\n",
        "        labels_def = None\n",
        "        self.model = self.model.cuda()\n",
        "        self.model.train(False)\n",
        "        with torch.no_grad():\n",
        "            for _, images, labels in self.train_loader:\n",
        "                if images_def is None:\n",
        "                    images_def = images\n",
        "                    labels_def = labels\n",
        "                else:\n",
        "                    \n",
        "                    images_def = torch.cat((images_tot, images), 0)\n",
        "                    labels_def = torch.cat((labels_tot, labels), 0)\n",
        "\n",
        "            images_def = images_tot.cuda()\n",
        "            features = self.model.feature_extractor(images_tot)\n",
        "            features = features.cpu()\n",
        "            rus = RandomUnderSampler()\n",
        "            features, labels_def = rus.fit_resample(features, labels_def)\n",
        "            print(features.size())   \n",
        "            self.clf=KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "            self.clf.fit(features, labels_tot)\n",
        "            print(\"fitted\")\n",
        "\n",
        "    def classifyKNN(self, images):\n",
        "        preds = []\n",
        "        self.model = self.model.cuda()\n",
        "        self.model.train(False)\n",
        "        with torch.no_grad():\n",
        "            features = self.model.feature_extractor(images)\n",
        "            features = features.cpu()\n",
        "            preds = self.clf.predict(features)\n",
        "            print(\"knn classified\")\n",
        "        return torch.Tensor(preds).cuda()\n",
        " \n",
        "\n",
        "    def classifySVM(self, images):\n",
        "        preds = []\n",
        "        self.model = self.model.cuda()\n",
        "        self.model.train(False)\n",
        "        with torch.no_grad():\n",
        "            features = self.model.feature_extractor(images)\n",
        "            features = features.cpu()\n",
        "            preds = self.clf.predict(features)\n",
        "            print(\"svm classified\")\n",
        "        return torch.Tensor(preds).cuda()\n",
        "\n",
        "    #DIFFERENT LOSSES\n",
        "\n",
        "    def less_forget_constraints(self,imgs, target, lambda_base=5):\n",
        "      \n",
        "      new_classes=10\n",
        "      old_classes= self.numclass-new_classes\n",
        "      output=self.model(imgs)\n",
        "      \n",
        "      #target = get_one_hot(target, self.numclass)\n",
        "      output, target = output.to(device), target.to(device)\n",
        "      loss_class= nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "      loss_cl=loss_class(output,target)\n",
        "      \n",
        "      if self.old_model == None:\n",
        "          return loss_cl/self.batchsize\n",
        "      \n",
        "      lambda_upd= lambda_base*np.sqrt(new_classes/old_classes)\n",
        "\n",
        "      old_features=self.old_model.feature_extractor(imgs)\n",
        "      new_features=self.model.feature_extractor(imgs)\n",
        "      old_features = F.normalize(old_features, p = 2)\n",
        "      new_features = F.normalize(new_features, p = 2)\n",
        "     \n",
        "\n",
        "      dist_loss = nn.CosineEmbeddingLoss(reduction='sum')\n",
        "      distillation_loss=dist_loss(old_features,new_features,torch.ones(old_features.size(0),).cuda())\n",
        "\n",
        "      batch_size=imgs.size(0)\n",
        "            \n",
        "      loss= (distillation_loss+loss_cl)/self.batchsize\n",
        "\n",
        "      return loss\n",
        "\n",
        "    def L2_L2_loss(self, indexs, imgs, target):\n",
        "        sigmoid=nn.Sigmoid()\n",
        "        startingNewLabels=self.numclass-len(self.exemplar_set)\n",
        "        output=self.model(imgs)\n",
        "        output_classification=output[:, startingNewLabels:]\n",
        "        target = get_one_hot(target, self.numclass)\n",
        "        target_classification=target[startingNewLabels:]\n",
        "        output=sigmoid(output)\n",
        "        output, target = output.to(device), target.to(device)\n",
        "        \n",
        "        loss= torch.nn.MSELoss(size_average=None, reduce=None, reduction='sum')\n",
        "        classification_loss=loss(output, target)\n",
        "        if self.old_model==None:\n",
        "          return classification_loss/self.batchsize\n",
        "        else:\n",
        "          \n",
        "          old_output=self.old_model(imgs)\n",
        "          old_class_size=old_output.shape[1]\n",
        "          output=output[:,:old_class_size]\n",
        "          old_output=sigmoid(old_output)\n",
        "          distillation_loss=loss(output, old_output)\n",
        "\n",
        "          return (classification_loss + distillation_loss)/self.batchsize\n",
        "\n",
        "    def CE_L2_loss(self, indexs, imgs, target):\n",
        "        startingNewLabels=self.numclass-len(self.exemplar_set)\n",
        "        output=self.model(imgs)\n",
        "        target_classification=target[startingNewLabels:]\n",
        "        output_classification=output[:, startingNewLabels:]\n",
        "        #target = get_one_hot(target, self.numclass)\n",
        "        output, target = output.to(device), target.to(device)\n",
        "        output_classification, target_classification = output.to(device), target.to(device)\n",
        "        loss= nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "        classification_loss=loss(output_classification, target_classification)\n",
        "        if self.old_model == None:\n",
        "            return classification_loss/self.batchsize\n",
        "        else:\n",
        "          L2_loss = nn.MSELoss()\n",
        "          sigmoid=nn.Sigmoid()\n",
        "          old_output=self.old_model(imgs)\n",
        "          old_output=sigmoid(old_output)\n",
        "         \n",
        "          \n",
        "          old_class_size=old_output.shape[1]\n",
        "          outputs=output[:,:old_class_size]\n",
        "          outputs=sigmoid(outputs)\n",
        "          \n",
        "          distillation_loss=L2_loss(outputs, old_output)\n",
        "\n",
        "          return (classification_loss + distillation_loss)/self.batchsize\n",
        "\n",
        "    \n",
        "\n",
        "    def test_SVM(self, test_loader):\n",
        "      X_test=[]\n",
        "      y_test=[]\n",
        "      \n",
        "      self.model.eval()\n",
        "      for _, images, labels in test_loader:        \n",
        "        labels=labels.to(device)\n",
        "        #images=images.view(128, 3, 32, 32)\n",
        "        images=images.type(torch.FloatTensor)\n",
        "        images=images.to(device)\n",
        "\n",
        "        features_map=self.model.feature_extractor(images)\n",
        "        \n",
        "        for f in features_map:\n",
        "           f = f.to('cpu')\n",
        "           X_test.append(f.detach().numpy())\n",
        "\n",
        "        for l in labels:\n",
        "              l = l.to('cpu')\n",
        "              y_test.append(l.detach().numpy())\n",
        "\n",
        "\n",
        "        predictions= self.clf.predict(X_test)\n",
        "        accuracy= accuracy_score(y_test, predictions)\n",
        "  \n",
        "      return accuracy\n",
        "      \n",
        "      \n",
        "       \n",
        "\n",
        "\n",
        "    # change the size of examplar\n",
        "    def afterTrain(self,accuracy):\n",
        "        self.model.eval()\n",
        "        m=int(self.memory_size/self.numclass)\n",
        "        self._reduce_exemplar_sets(m)\n",
        "        for i in range(self.numclass-self.task_size,self.numclass):\n",
        "            print('construct class %s examplar:'%(i),end='')\n",
        "            images=self.train_dataset.get_image_class(i)\n",
        "            #class_mean, _ = self.compute_class_mean(self.train_dataset.get_image_class(i),self.transform)\n",
        "            #self.class_mean_set.append(class_mean)\n",
        "            self._construct_exemplar_set(images,m)\n",
        "        self.numclass+=self.task_size\n",
        "        self.compute_exemplar_class_mean()\n",
        "        self.model.train()\n",
        "        self.training_KNN(self.n_neighbors) # change to training_KNN to train KNN classifier\n",
        "        SVM_accuracy=float(self._test(self.test_loader,0)) #'1' to classify by using fc\n",
        "        Current_accuracy = float(self._test(self.test_current_classes_loader,0))\n",
        "        print(\"NME accuracy：\"+str(SVM_accuracy))\n",
        "        print(\"current accuracy\",Current_accuracy)\n",
        "        \n",
        "        self.old_model=copy.deepcopy(self.model)\n",
        "        self.old_model.to(device)\n",
        "        self.old_model.eval()\n",
        "        return SVM_accuracy,Current_accuracy\n",
        "\n",
        "\n",
        "    def _construct_exemplar_set(self, images, m):\n",
        "\n",
        "        class_mean, feature_extractor_output = self.compute_class_mean(images, self.transform)\n",
        "        class_var, feature_extractor_output_var = self.compute_class_variance(images, self.transform)\n",
        "\n",
        "        exemplar = []\n",
        "        now_class_mean = np.zeros((1, 512))\n",
        "        now_class_variance = np.zeros((1, 512))   \n",
        "        if self.random_selection:\n",
        "          indexes = []\n",
        "          i=0\n",
        "          while i != (m):\n",
        "            targ= np.random.randint(m)\n",
        "            if targ not in indexes:\n",
        "              exemplar.append(images[targ])\n",
        "              i=i+1\n",
        "\n",
        "          print(\"the size of exemplar :%s\" % (str(len(exemplar))))\n",
        "          self.exemplar_set.append(exemplar)\n",
        "          #self.exemplar_set.append(images)\n",
        "        else:\n",
        "           indexes = []\n",
        "        for i in range(m):\n",
        "            x = class_mean - (now_class_mean + feature_extractor_output) / (i + 1)\n",
        "            x = np.linalg.norm(x, axis=1)\n",
        "            index = np.argmin(x)\n",
        "            while index in indexes:\n",
        "              x[index] = 9999999\n",
        "              index = np.argmin(x)\n",
        "            indexes += index \n",
        "            now_class_mean += feature_extractor_output[index]\n",
        "            exemplar.append(images[index])\n",
        "            '''\n",
        "          else:            \n",
        "            x = class_var - ((now_class_variance + feature_extractor_output_var**2)/(i)-class_mean**2)\n",
        "            x = np.linalg.norm(x, axis=1)\n",
        "            index = np.argmin(x)\n",
        "            while index in indexes:\n",
        "              x[index] = 9999999\n",
        "              index = np.argmin(x)\n",
        "            indexes += index \n",
        "            now_class_variance += feature_extractor_output_var[index]**2\n",
        "            exemplar.append(images[index])\n",
        "           '''\n",
        "        print(\"the size of exemplar :%s\" % (str(len(exemplar))))\n",
        "        self.exemplar_set.append(exemplar)\n",
        "        #self.exemplar_set.append(images)\n",
        "\n",
        "    def _reduce_exemplar_sets(self, m):\n",
        "        for index in range(len(self.exemplar_set)):\n",
        "            self.exemplar_set[index] = self.exemplar_set[index][:m]\n",
        "            print('Size of class %d examplar: %s' % (index, str(len(self.exemplar_set[index]))))\n",
        "\n",
        "\n",
        "\n",
        "    def Image_transform(self, images, transform):\n",
        "        data = transform(Image.fromarray(images[0])).unsqueeze(0)\n",
        "        for index in range(1, len(images)):\n",
        "            data = torch.cat((data, self.transform(Image.fromarray(images[index])).unsqueeze(0)), dim=0)\n",
        "        return data\n",
        "\n",
        "    def compute_class_mean(self, images, transform):\n",
        "        x = self.Image_transform(images, transform).to(device)\n",
        "        feature_extractor_output = F.normalize(self.model.feature_extractor(x).detach()).cpu().numpy()\n",
        "        class_mean = np.mean(feature_extractor_output, axis=0)\n",
        "        return class_mean, feature_extractor_output\n",
        "\n",
        "    def compute_class_variance(self, images, transform):\n",
        "        x = self.Image_transform(images, transform).to(device)\n",
        "        feature_extractor_output = F.normalize(self.model.feature_extractor(x).detach()).cpu().numpy()\n",
        "        class_mean = np.var(feature_extractor_output, axis=0)\n",
        "        return class_mean, feature_extractor_output\n",
        "\n",
        "    def compute_exemplar_class_mean(self):\n",
        "        self.class_mean_set = []\n",
        "        for index in range(len(self.exemplar_set)):\n",
        "            print(\"compute the class mean of %s\"%(str(index)))\n",
        "            exemplar=self.exemplar_set[index]\n",
        "            #exemplar=self.train_dataset.get_image_class(index)\n",
        "            class_mean, _ = self.compute_class_mean(exemplar, self.transform)\n",
        "            class_mean_,_=self.compute_class_mean(exemplar,self.classify_transform)\n",
        "            class_mean=(class_mean/np.linalg.norm(class_mean)+class_mean_/np.linalg.norm(class_mean_))/2\n",
        "            self.class_mean_set.append(class_mean)\n",
        "\n",
        "    def classify(self, test):\n",
        "        result = []\n",
        "        test = F.normalize(self.model.feature_extractor(test).detach()).cpu().numpy()\n",
        "        #test = self.model.feature_extractor(test).detach().cpu().numpy()\n",
        "        class_mean_set = np.array(self.class_mean_set)\n",
        "        for target in test:\n",
        "            x = target - class_mean_set\n",
        "            x = np.linalg.norm(x, ord=2, axis=1)\n",
        "            x = np.argmin(x)\n",
        "            result.append(x)\n",
        "        return torch.tensor(result)\n",
        "\n",
        "    def getNet(self):\n",
        "        return copy.deepcopy(self.old_model)\n",
        "\n",
        "    def getTestLoader(self):\n",
        "        return self.test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jkcImiyNcGf"
      },
      "source": [
        "\n",
        "def display_conf_matrix(confusion_matrix,display=False,save=False,path=None):\n",
        "\tn_classes = len(confusion_matrix)\n",
        "\n",
        "\tticks = [i-0.5 for i in range(n_classes)]\n",
        "\n",
        "\tfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,8))\n",
        "\n",
        "\tim = ax.imshow(confusion_matrix, interpolation='nearest', cmap=plt.cm.jet)\n",
        "\n",
        "\ttick_strings = []\n",
        "\tfor i in range(n_classes):\n",
        "\t\tif (i+1)%10 == 0:\n",
        "\t\t\ttick_strings.append(str(i+1))\n",
        "\t\telse:\n",
        "\t\t\ttick_strings.append('')\n",
        "\n",
        "\tax.set(yticks=ticks, \n",
        "\t       xticks=ticks,\n",
        "\t       yticklabels=tick_strings, \n",
        "\t\t\txticklabels=tick_strings)\n",
        "\n",
        "\tax.yaxis.set_major_locator(ticker.IndexLocator(base=1, offset=0.5))\n",
        "\tax.xaxis.set_major_locator(ticker.IndexLocator(base=1, offset=0.5))\n",
        "\n",
        "\tax.tick_params(length=0, labelsize='14')\n",
        "\n",
        "\tax.set_xlabel('Predicted class', labelpad=14, fontsize='16')\n",
        "\tax.set_ylabel('True class', labelpad=14, rotation=90, fontsize='16')\n",
        "\n",
        "\tif display: \n",
        "\t\tplt.show()\n",
        "\tplt.close();\n",
        "\n",
        "\t# Save figures\n",
        "\tif save:\n",
        "\t\tif path == None:\n",
        "\t\t\traise RuntimeError(\"Devi passare il path alla funzione display_conf_matrix\")\n",
        "\n",
        "\t\tfig.savefig(path+'/conf_matrix.png')\n",
        "\t\n",
        "\treturn\n",
        "\n",
        "def get_conf_matrix(net, test_dataloader, device):\n",
        "\tnet.train(False)\n",
        "\t# flag \n",
        "\tFIRST = True \n",
        "\n",
        "\ty_pred = None\n",
        "\ty_test = None\n",
        "\n",
        "\tfor steps, (index, images, labels) in enumerate(test_dataloader):\n",
        "\t\timages = images.to(device)\n",
        "\t\tlabels = labels.to(device)\n",
        "\n",
        "\t\t# Forward Pass\n",
        "\t\toutputs = net(images)\n",
        "\n",
        "\t\t# Get predictions\n",
        "\t\t_, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "\t\t# concatenate predictions and labels\n",
        "\t\tif FIRST : \n",
        "\t\t\ty_pred = preds.detach().cpu().clone()\n",
        "\t\t\ty_test = labels.detach().cpu().clone()\n",
        "\t\t\tFIRST=False \n",
        "\t\telse: \n",
        "\t\t\ty_pred = torch.cat((y_pred,preds.cpu()))\n",
        "\t\t\ty_test = torch.cat((y_test,labels.cpu()))\n",
        "\t\n",
        "\treturn confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdUF84x6VC7c",
        "outputId": "25273929-dc58-494d-8956-4f5338d180a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from matplotlib import ticker\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic=True\n",
        "torch.backends.cudnn.benchmark=False\n",
        "np.random.seed(0)\n",
        "\n",
        "numclass=10\n",
        "feature_extractor=resnet18_cbam()\n",
        "img_size=32\n",
        "batch_size=128\n",
        "task_size=10\n",
        "memory_size=2000\n",
        "epochs=1\n",
        "learning_rate=2\n",
        "\n",
        "model=iCaRLmodel(numclass,feature_extractor,batch_size,task_size,memory_size,epochs,learning_rate)\n",
        "#model.model.load_state_dict(torch.load('model/ownTry_accuracy:84.000_KNN_accuracy:84.000_increment:10_net.pkl'))\n",
        "acc = []\n",
        "ac=[]\n",
        "accu = 0\n",
        "for i in range(10):\n",
        "    model.beforeTrain()\n",
        "    model.train()\n",
        "    accuracy, current= model.afterTrain(accu)\n",
        "    acc.append(accuracy)\n",
        "    ac.append(current)\n",
        "\n",
        "print(acc)\n",
        "print(ac)\n",
        "\n",
        "lastNet = model.getNet()\n",
        "testLoader = model.getTestLoader()\n",
        "confusion_matrix = get_conf_matrix(lastNet, testLoader, device)\n",
        "display_conf_matrix(confusion_matrix, True)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "the size of test current classses set is (1000, 32, 32, 3)\n",
            "the size of test label current classes is (1000,)\n",
            "the size of train set is (5000, 32, 32, 3)\n",
            "the size of train label is (5000,)\n",
            "the size of test set is (1000, 32, 32, 3)\n",
            "the size of test label is (1000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:106: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:108: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:99: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:0,step:0,loss:0.663\n",
            "epoch:0,step:1,loss:2.536\n",
            "epoch:0,step:2,loss:1.225\n",
            "epoch:0,step:3,loss:0.403\n",
            "epoch:0,step:4,loss:0.427\n",
            "epoch:0,step:5,loss:0.353\n",
            "epoch:0,step:6,loss:0.421\n",
            "epoch:0,step:7,loss:0.386\n",
            "epoch:0,step:8,loss:0.386\n",
            "epoch:0,step:9,loss:0.344\n",
            "epoch:0,step:10,loss:0.332\n",
            "epoch:0,step:11,loss:0.322\n",
            "epoch:0,step:12,loss:0.314\n",
            "epoch:0,step:13,loss:0.372\n",
            "epoch:0,step:14,loss:0.356\n",
            "epoch:0,step:15,loss:0.338\n",
            "epoch:0,step:16,loss:0.328\n",
            "epoch:0,step:17,loss:0.318\n",
            "epoch:0,step:18,loss:0.312\n",
            "epoch:0,step:19,loss:0.349\n",
            "epoch:0,step:20,loss:0.329\n",
            "epoch:0,step:21,loss:0.299\n",
            "epoch:0,step:22,loss:0.307\n",
            "epoch:0,step:23,loss:0.288\n",
            "epoch:0,step:24,loss:0.300\n",
            "epoch:0,step:25,loss:0.286\n",
            "epoch:0,step:26,loss:0.323\n",
            "epoch:0,step:27,loss:0.301\n",
            "epoch:0,step:28,loss:0.308\n",
            "epoch:0,step:29,loss:0.294\n",
            "epoch:0,step:30,loss:0.273\n",
            "epoch:0,step:31,loss:0.285\n",
            "epoch:0,step:32,loss:0.262\n",
            "epoch:0,step:33,loss:0.290\n",
            "epoch:0,step:34,loss:0.273\n",
            "epoch:0,step:35,loss:0.271\n",
            "epoch:0,step:36,loss:0.297\n",
            "epoch:0,step:37,loss:0.280\n",
            "epoch:0,step:38,loss:0.262\n",
            "epoch:0,step:39,loss:0.304\n",
            "epoch:0,step:0,loss:0.338\n",
            "epoch:0,step:1,loss:0.270\n",
            "epoch:0,step:2,loss:0.282\n",
            "epoch:0,step:3,loss:0.291\n",
            "epoch:0,step:4,loss:0.273\n",
            "epoch:0,step:5,loss:0.247\n",
            "epoch:0,step:6,loss:0.269\n",
            "epoch:0,step:7,loss:0.279\n",
            "epoch:0,step:8,loss:0.266\n",
            "epoch:0,step:9,loss:0.235\n",
            "epoch:0,step:10,loss:0.242\n",
            "epoch:0,step:11,loss:0.259\n",
            "epoch:0,step:12,loss:0.247\n",
            "epoch:0,step:13,loss:0.273\n",
            "epoch:0,step:14,loss:0.256\n",
            "epoch:0,step:15,loss:0.248\n",
            "epoch:0,step:16,loss:0.246\n",
            "epoch:0,step:17,loss:0.245\n",
            "epoch:0,step:18,loss:0.269\n",
            "epoch:0,step:19,loss:0.256\n",
            "epoch:0,step:20,loss:0.247\n",
            "epoch:0,step:21,loss:0.266\n",
            "epoch:0,step:22,loss:0.247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-7282b607cf4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeforeTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafterTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-1cf3de482494>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m                   \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                   \u001b[0;31m#output = self.model(images)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                   \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                   \u001b[0;31m#loss_value = self.CE_L2_loss(indexs, images, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                   \u001b[0;31m#loss_value = self.L2_L2_loss(indexs, images, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-1cf3de482494>\u001b[0m in \u001b[0;36m_compute_loss\u001b[0;34m(self, indexs, imgs, target)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold_model\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-1cf3de482494>\u001b[0m in \u001b[0;36mget_one_hot\u001b[0;34m(target, num_class)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz4Ft_EJyrDT"
      },
      "source": [
        "acctot = [int(el[0]) for el in acc ]\n",
        "accurr = [int(el[1]) for el in acc ]\n",
        "print(acctot)\n",
        "print(accurr)\n",
        "#FINET1\n",
        "#[71, 41, 26, 21, 17, 13, 12, 10, 9, 8]\n",
        "#[71, 83, 79, 84, 88, 83, 89, 86, 88, 85]\n",
        "#[78, 41, 27, 21, 17, 14, 12, 10, 9, 9]\n",
        "#[78, 82, 81, 84, 89, 89, 90, 87, 87, 91]\n",
        "#[87, 43, 26, 20, 17, 14, 11, 11, 10, 8]\n",
        "#[87, 87, 78, 83, 89, 87, 83, 90, 91, 85]\n",
        "\n",
        "#LWF\n",
        "#[79, 64, 56, 50, 45, 41, 38, 37, 36, 36]\n",
        "#[79, 70, 67, 60, 64, 65, 56, 62, 61, 66]\n",
        "#[86, 68, 59, 53, 48, 43, 42, 39, 38, 36]\n",
        "#[86, 71, 70, 68, 58, 56, 63, 68, 59, 52\n",
        "#[80, 64, 60, 53, 46, 43, 40, 40, 39, 37]\n",
        "#[80, 72, 72, 59, 67, 60, 53, 69, 67, 47]\n",
        "\n",
        "#[tensor(86), tensor(73), tensor(69), tensor(64), tensor(60), tensor(56), tensor(54), tensor(51), tensor(49), tensor(47)]'\n",
        "#order\n",
        "#[tensor(86), tensor(75), tensor(70), tensor(66), tensor(63), tensor(60), tensor(58), tensor(55), tensor(53), tensor(50)]]'\n",
        "#rand1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9B5HMyRl-uu"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "accuracy = np.array([88,76,74,69,62,58,56,54,52,50])\n",
        "accuracy2 = np.array([85,73,71,65,60,56,53,52,49,46])\n",
        "accuracy3 = accuracy2 - 2\n",
        "classes = np.array([10,20,30,40,50,60,70,80,90,100])\n",
        "data_preproc = pd.DataFrame({\n",
        "    'Year':classes,\n",
        "    'Ciao': accuracy,\n",
        "    'Caoi': accuracy2,\n",
        "    'Caio': accuracy3})\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.despine(left=True)\n",
        "\n",
        "sns.lineplot(x='Year', y='value', hue='variable',style=\"variable\",\n",
        " markers=True, dashes=False, \n",
        "             data=pd.melt(data_preproc, ['Year']))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}